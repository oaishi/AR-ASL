{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk postag list - https://medium.com/@gianpaul.r/tokenization-and-parts-of-speech-pos-tagging-in-pythons-nltk-library-2d30f70af13b\n",
    "# CC coordinating conjunction\n",
    "# CD cardinal digit\n",
    "# DT determiner\n",
    "# EX existential there (like: “there is” … think of it like “there exists”)\n",
    "# FW foreign word\n",
    "# IN preposition/subordinating conjunction\n",
    "# JJ adjective ‘big’\n",
    "# JJR adjective, comparative ‘bigger’\n",
    "# JJS adjective, superlative ‘biggest’\n",
    "# LS list marker 1)\n",
    "# MD modal could, will\n",
    "# NN noun, singular ‘desk’\n",
    "# NNS noun plural ‘desks’\n",
    "# NNP proper noun, singular ‘Harrison’\n",
    "# NNPS proper noun, plural ‘Americans’\n",
    "# PDT predeterminer ‘all the kids’\n",
    "# POS possessive ending parent’s\n",
    "# PRP personal pronoun I, he, she\n",
    "# PRP$ possessive pronoun my, his, hers\n",
    "# RB adverb very, silently,\n",
    "# RBR adverb, comparative better\n",
    "# RBS adverb, superlative best\n",
    "# RP particle give up\n",
    "# TO, to go ‘to’ the store.\n",
    "# UH interjection, errrrrrrrm\n",
    "# VB verb, base form take\n",
    "# VBD verb, past tense took\n",
    "# VBG verb, gerund/present participle taking\n",
    "# VBN verb, past participle taken\n",
    "# VBP verb, sing. present, non-3d take\n",
    "# VBZ verb, 3rd person sing. present takes\n",
    "# WDT wh-determiner which\n",
    "# WP wh-pronoun who, what\n",
    "# WP$ possessive wh-pronoun whose\n",
    "# WRB wh-abverb where, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.nltk.org/book/ch05.html\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "import numpy as np\n",
    "import cv2\n",
    "# https://www.nltk.org/book/ch05.html\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import requests\n",
    "import cv2\n",
    "import os.path\n",
    "from googletrans import Translator\n",
    "from pytesseract import Output\n",
    "\n",
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    import Image\n",
    "import pytesseract\n",
    "\n",
    "\n",
    "\n",
    "sanity_checkmark = ['CD', 'EX', 'JJ', 'MD', 'NN', 'NNS', 'NNP', 'NNPS', 'PRP', 'PRP$', 'RB', 'VB', 'WDT', 'WP', 'WP$', 'WRB' ]\n",
    "\n",
    "# punctuation, plural, adjective checking \n",
    "\n",
    "def pos_tag_sanity(text):\n",
    "    text = word_tokenize(text)\n",
    "    text = nltk.pos_tag(text)\n",
    "    asl_text = []\n",
    "    \n",
    "    for i in range(len(text)):\n",
    "        if text[i][1] in sanity_checkmark:\n",
    "            asl_text.append(text[i][0])\n",
    "            \n",
    "    return asl_text\n",
    "\n",
    "# print(pos_tag_sanity(\"And now is for something completely different. Eat were they\"))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listToStr(s):\n",
    "    return ' '.join([str(elem) for elem in s]) \n",
    "\n",
    "def lettersToStr(s):\n",
    "    return ''.join([str(elem) for elem in s]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gettranslation(text):\n",
    "    translator = Translator()\n",
    "    translated = translator.translate(text) \n",
    "    return translated.text\n",
    "\n",
    "def detectlang(text):\n",
    "    translator = Translator()\n",
    "    detector = translator.detect(text)\n",
    "    return detector.lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text You never are going to get\n",
      "nowhere st\n",
      "do not try.\n",
      "lang es\n"
     ]
    }
   ],
   "source": [
    "# text = word_tokenize(\"man men\")\n",
    "# print(nltk.pos_tag(text))\n",
    "\n",
    "# pos_tag_sanity('dog dogs')\n",
    "\n",
    "text = (pytesseract.image_to_string(Image.open('test_6.jpg'))).lower()\n",
    "language = detectlang(text)\n",
    "if language != \"en\":\n",
    "    print('text',gettranslation(text))\n",
    "    print('lang',language)\n",
    "else:    \n",
    "    print('here',text)\n",
    "# print('text',text)\n",
    "\n",
    "# print('pos_tag_sanity',pos_tag_sanity(text))\n",
    "# text = word_tokenize(text)\n",
    "# print(nltk.pos_tag(text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AR Portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/\n",
    "#show-webcam-and-video-simultaneously\n",
    "def showvideo2(c,caption):\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    global dim, font\n",
    "    cap_video = cv2.VideoCapture(c)    \n",
    "\n",
    "    # Check if camera opened successfully\n",
    "    if (cap_video.isOpened()== False):\n",
    "        print(\"Error opening video stream or file\")\n",
    "        \n",
    "    while(cap_video.isOpened()):\n",
    "        ret, frame = cap_video.read()\n",
    "        ret_cam, frame_cam = cap.read()\n",
    "        if ret == True and ret_cam== True :\n",
    "            frame = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
    "            frame_cam = cv2.resize(frame_cam, dim, interpolation = cv2.INTER_AREA)\n",
    "            \n",
    "            # Using cv2.putText() method \n",
    "            #https://www.geeksforgeeks.org/python-opencv-cv2-puttext-method/\n",
    "            frame = cv2.putText(frame, caption, (50, 450), font,  \n",
    "                               0.5, (255, 255, 255), 2, cv2.LINE_AA) \n",
    "        \n",
    "            img3 = cv2.hconcat([frame,frame_cam])   \n",
    "            cv2.imshow(WindowName,img3)\n",
    "            cv2.moveWindow(WindowName, 0, 0)\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "#         else:\n",
    "        if ret != True:\n",
    "            frame = None\n",
    "            break\n",
    "\n",
    "            \n",
    "    cap_video.release()    \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "WindowName=\"Main View\"\n",
    "dim = (500, 500)\n",
    "loading_img = cv2.imread('loading.jpg', cv2.IMREAD_COLOR )  \n",
    "loading_img = cv2.resize(loading_img, dim, interpolation = cv2.INTER_AREA) \n",
    "\n",
    "# https://stackoverflow.com/a/54059166\n",
    "def boundary_mark(frame):\n",
    "    global dim\n",
    "    d = pytesseract.image_to_data(frame, output_type=Output.DICT)\n",
    "    n_boxes = len(d['level'])\n",
    "    for i in range(1,n_boxes):\n",
    "        (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    frame = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA) \n",
    "    \n",
    "    return frame\n",
    "   \n",
    "# https://www.learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/\n",
    "def showvideo(c,frame_cam,caption):\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    cap_video = cv2.VideoCapture(c)    \n",
    "\n",
    "    # Check if camera opened successfully\n",
    "    if (cap_video.isOpened()== False):\n",
    "        print(\"Error opening video stream or file\")\n",
    "        \n",
    "    while(cap_video.isOpened()):\n",
    "        ret, frame = cap_video.read()\n",
    "        if ret == True:\n",
    "            frame = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
    "            \n",
    "            # Using cv2.putText() method \n",
    "            #https://www.geeksforgeeks.org/python-opencv-cv2-puttext-method/\n",
    "            frame = cv2.putText(frame, caption, (50, 450), cv2.FONT_HERSHEY_SIMPLEX , 0.5, (255, 255, 255), 2, cv2.LINE_AA) \n",
    "        \n",
    "            img3 = cv2.hconcat([frame,frame_cam])   \n",
    "            cv2.imshow(WindowName,img3)\n",
    "            cv2.moveWindow(WindowName, 0, 0)\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "#         else:\n",
    "        if ret != True:\n",
    "            frame = None\n",
    "            break\n",
    "\n",
    "            \n",
    "    cap_video.release()    \n",
    "    cv2.destroyAllWindows()    \n",
    "\n",
    "\n",
    "def find_words(frame,loading_img=loading_img):\n",
    "    \n",
    "    f = open('non_ASL_word_list.txt', 'r')\n",
    "    nonASLwords = f.readlines()\n",
    "    f.close()   \n",
    "       \n",
    "    text = (pytesseract.image_to_string(frame)).lower()\n",
    "        \n",
    "    language = detectlang(text)\n",
    "    if language != \"en\":\n",
    "        text = gettranslation(text)\n",
    "        \n",
    "    frame_1 = boundary_mark(frame)\n",
    "#     frame_1 = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
    "    img3 = cv2.hconcat([loading_img,frame_1])\n",
    "    \n",
    "    modified_list_words = pos_tag_sanity(text)\n",
    "\n",
    "    modified_urls = [ i + \"/\" + i + \"-abc.mp4\" if len(i) == 1 else i[0] + \"/\" + i + \".mp4\" if i != \"bye\" else \"bye-wave.mp4\" for i in modified_list_words]\n",
    "        \n",
    "    print(modified_list_words,modified_urls)\n",
    "    # Read URLs from handspeak.com\n",
    "    # https://github.com/esqu1/ASLetter    \n",
    "    for i, url in enumerate(modified_urls):\n",
    "        \n",
    "        cv2.imshow(WindowName,img3)\n",
    "        cv2.moveWindow(WindowName, 0, 0)\n",
    "        cv2.waitKey(delay = 1)\n",
    "                \n",
    "        if url in nonASLwords:\n",
    "            print('trying_dict')\n",
    "            letters = list(modified_list_words[i])\n",
    "            for j, l in enumerate(letters):\n",
    "                if l.isalpha():\n",
    "                    showvideo(\"letters/%s-abc.mp4\" % l,frame_1, listToStr(modified_list_words[:i])+\" \"+ lettersToStr(letters[:j]) + \"*\"+ l + \"*\"+\n",
    "                                                     lettersToStr(letters[(j+1):]) +\" \"+ listToStr(modified_list_words[(i+1):])) \n",
    "                    \n",
    "        elif os.path.isfile(\"data/\" + url):\n",
    "            print(\"playing existing video\")\n",
    "            showvideo(\"data/\" + url, frame_1,listToStr(modified_list_words[:i])+\" *\"+ modified_list_words[i] + \"* \"+ listToStr(modified_list_words[(i+1):])) \n",
    "        else:    \n",
    "            r = requests.get(\"https://handspeak.com/word/\" + url)\n",
    "            if r.text[:15] == \"<!DOCTYPE html>\":\n",
    "                nonASLwords.append(url)\n",
    "                letters = list(modified_list_words[i])\n",
    "                \n",
    "                for j, l in enumerate(letters):\n",
    "                    if l.isalpha():\n",
    "                        showvideo(\"letters/%s-abc.mp4\" % l, frame_1,listToStr(modified_list_words[:i])+\" \"+ lettersToStr(letters[:j]) + \"*\"+ l + \"*\"+\n",
    "                                                     lettersToStr(letters[(j+1):]) +\" \"+ listToStr(modified_list_words[(i+1):])) \n",
    "                        \n",
    "            else: \n",
    "\n",
    "                f = open(\"data/\" + url, 'wb')\n",
    "                for chunk in r.iter_content(chunk_size=255):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "                f.close()\n",
    "                showvideo(\"data/\" + url, frame_1,listToStr(modified_list_words[:i])+\" *\"+ modified_list_words[i] + \"* \"+ listToStr(modified_list_words[(i+1):])) \n",
    "\n",
    "\n",
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    count = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        count += 1\n",
    "        if count%200 == 0:\n",
    "            count = count%200\n",
    "#             find_words(cv2.imread('test_7.jpg'))\n",
    "            find_words(frame)\n",
    "        if not ret:\n",
    "            print(\"Unable to capture video\")\n",
    "            break \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break            \n",
    "\n",
    "        frame_1 = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)   \n",
    "\n",
    "        # Horizontally concatenate the 2 images\n",
    "        img3 = cv2.hconcat([loading_img,frame_1])\n",
    "\n",
    "        # Display the concatenated image\n",
    "        cv2.imshow(WindowName,img3)\n",
    "        cv2.moveWindow(WindowName, 0, 0)\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unit', 'four', 'we', 'aware'] ['u/unit.mp4', 'f/four.mp4', 'w/we.mp4', 'a/aware.mp4']\n",
      "playing existing video\n",
      "playing existing video\n",
      "playing existing video\n",
      "[] []\n",
      "['unit', 'our', '_', 'we', 'aware'] ['u/unit.mp4', 'o/our.mp4', '_/_-abc.mp4', 'w/we.mp4', 'a/aware.mp4']\n",
      "playing existing video\n",
      "playing existing video\n",
      "playing existing video\n",
      "['unit', 'four'] ['u/unit.mp4', 'f/four.mp4']\n",
      "playing existing video\n"
     ]
    }
   ],
   "source": [
    "# https://www.geeksforgeeks.org/python-face-recognition-using-gui/\n",
    "import tkinter as tk \n",
    "from tkinter import Message, Text \n",
    "from PIL import ImageTk \n",
    "import tkinter.ttk as ttk \n",
    "import tkinter.font as font\n",
    "\n",
    "\n",
    "window = tk.Tk() \n",
    "# https://yagisanatode.com/2018/02/23/how-do-i-change-the-size-and-position-of-the-main-window-in-tkinter-and-python-3/\n",
    "window.geometry(\"750x400\") #Width x Height\n",
    "window.title(\"AR_ASL\") \n",
    "window.configure(background ='white') \n",
    "window.grid_rowconfigure(0, weight = 1) \n",
    "window.grid_columnconfigure(0, weight = 1) \n",
    "message = tk.Label( \n",
    "    window, text =\"Language should not be a barrier.\", \n",
    "    bg =\"green\", fg = \"white\", width = 32, \n",
    "    height = 3, font = ('times', 30, 'italic')) \n",
    "\n",
    "message.place(x = 20, y = 20) \n",
    "\n",
    "message_1 = tk.Label( \n",
    "    window, text =\"Click Start to begin the journey\", \n",
    "    bg =\"white\", fg = \"black\", width = 30, \n",
    "    height = 3, font = ('times', 30, 'bold')) \n",
    "\n",
    "message_1.place(x = 20, y = 150) \n",
    "\n",
    "takeImg = tk.Button(window, text =\"Start\", \n",
    "command = main, fg =\"white\", bg =\"green\", \n",
    "width = 20, height = 3, activebackground = \"Red\", \n",
    "font =('times', 15, ' bold ')) \n",
    "takeImg.place(x = 20, y = 300) \n",
    "\n",
    "quitWindow = tk.Button(window, text =\"Quit\", \n",
    "command = window.destroy, fg =\"white\", bg =\"green\", \n",
    "width = 20, height = 3, activebackground = \"Red\", \n",
    "font =('times', 15, ' bold ')) \n",
    "quitWindow.place(x = 480, y = 300) \n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
