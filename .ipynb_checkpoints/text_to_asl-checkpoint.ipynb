{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk postag list - https://medium.com/@gianpaul.r/tokenization-and-parts-of-speech-pos-tagging-in-pythons-nltk-library-2d30f70af13b\n",
    "# CC coordinating conjunction\n",
    "# CD cardinal digit\n",
    "# DT determiner\n",
    "# EX existential there (like: “there is” … think of it like “there exists”)\n",
    "# FW foreign word\n",
    "# IN preposition/subordinating conjunction\n",
    "# JJ adjective ‘big’\n",
    "# JJR adjective, comparative ‘bigger’\n",
    "# JJS adjective, superlative ‘biggest’\n",
    "# LS list marker 1)\n",
    "# MD modal could, will\n",
    "# NN noun, singular ‘desk’\n",
    "# NNS noun plural ‘desks’\n",
    "# NNP proper noun, singular ‘Harrison’\n",
    "# NNPS proper noun, plural ‘Americans’\n",
    "# PDT predeterminer ‘all the kids’\n",
    "# POS possessive ending parent’s\n",
    "# PRP personal pronoun I, he, she\n",
    "# PRP$ possessive pronoun my, his, hers\n",
    "# RB adverb very, silently,\n",
    "# RBR adverb, comparative better\n",
    "# RBS adverb, superlative best\n",
    "# RP particle give up\n",
    "# TO, to go ‘to’ the store.\n",
    "# UH interjection, errrrrrrrm\n",
    "# VB verb, base form take\n",
    "# VBD verb, past tense took\n",
    "# VBG verb, gerund/present participle taking\n",
    "# VBN verb, past participle taken\n",
    "# VBP verb, sing. present, non-3d take\n",
    "# VBZ verb, 3rd person sing. present takes\n",
    "# WDT wh-determiner which\n",
    "# WP wh-pronoun who, what\n",
    "# WP$ possessive wh-pronoun whose\n",
    "# WRB wh-abverb where, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = word_tokenize(\"man men\")\n",
    "# print(nltk.pos_tag(text))\n",
    "\n",
    "# pos_tag_sanity('dog dogs')\n",
    "\n",
    "text = (pytesseract.image_to_string(Image.open('test.jpg'))).lower()\n",
    "\n",
    "print('text',text)\n",
    "\n",
    "print('pos_tag_sanity',pos_tag_sanity(text))\n",
    "text = word_tokenize(text)\n",
    "print(nltk.pos_tag(text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.nltk.org/book/ch05.html\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "import numpy as np\n",
    "import cv2\n",
    "# https://www.nltk.org/book/ch05.html\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import requests\n",
    "import cv2\n",
    "import os.path\n",
    "\n",
    "try:\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    import Image\n",
    "import pytesseract\n",
    "\n",
    "\n",
    "\n",
    "sanity_checkmark = ['CD', 'EX', 'JJ', 'MD', 'NN', 'NNS', 'NNP', 'NNPS', 'PRP', 'PRP$', 'RB', 'VB', 'WDT', 'WP', 'WP$', 'WRB' ]\n",
    "\n",
    "# punctuation, plural, adjective checking \n",
    "\n",
    "def pos_tag_sanity(text):\n",
    "    text = word_tokenize(text)\n",
    "    text = nltk.pos_tag(text)\n",
    "    asl_text = []\n",
    "    \n",
    "    for i in range(len(text)):\n",
    "        if text[i][1] in sanity_checkmark:\n",
    "            asl_text.append(text[i][0])\n",
    "            \n",
    "    return asl_text\n",
    "\n",
    "# print(pos_tag_sanity(\"And now is for something completely different. Eat were they\"))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listToStr(s):\n",
    "    return ' '.join([str(elem) for elem in s]) \n",
    "\n",
    "def lettersToStr(s):\n",
    "    return ''.join([str(elem) for elem in s]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AR Portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WindowName=\"Main View\"\n",
    "dim = (500, 500)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "loading_img = cv2.imread('loading.jpg', cv2.IMREAD_COLOR )  \n",
    "loading_img = cv2.resize(loading_img, dim, interpolation = cv2.INTER_AREA) \n",
    "\n",
    "# https://www.learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/\n",
    "def showvideo(c,caption):\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    global dim, font\n",
    "    cap_video = cv2.VideoCapture(c)    \n",
    "\n",
    "    # Check if camera opened successfully\n",
    "    if (cap_video.isOpened()== False):\n",
    "        print(\"Error opening video stream or file\")\n",
    "        \n",
    "    while(cap_video.isOpened()):\n",
    "        ret, frame = cap_video.read()\n",
    "        ret_cam, frame_cam = cap.read()\n",
    "        if ret == True and ret_cam== True :\n",
    "            frame = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
    "            frame_cam = cv2.resize(frame_cam, dim, interpolation = cv2.INTER_AREA)\n",
    "            \n",
    "            # Using cv2.putText() method \n",
    "            #https://www.geeksforgeeks.org/python-opencv-cv2-puttext-method/\n",
    "            frame = cv2.putText(frame, caption, (50, 450), font,  \n",
    "                               0.5, (255, 255, 255), 2, cv2.LINE_AA) \n",
    "        \n",
    "            img3 = cv2.hconcat([frame,frame_cam])   \n",
    "            cv2.imshow(WindowName,img3)\n",
    "            cv2.moveWindow(WindowName, 0, 0)\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "#         else:\n",
    "        if ret != True:\n",
    "            frame = None\n",
    "            break\n",
    "\n",
    "            \n",
    "    cap_video.release()    \n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def main(frame,loading_img=loading_img):\n",
    "    \n",
    "    f = open('non_ASL_word_list.txt', 'r')\n",
    "    nonASLwords = f.readlines()\n",
    "    f.close()\n",
    "    \n",
    "    frame_1 = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
    "    img3 = cv2.hconcat([loading_img,frame_1])\n",
    "\n",
    "#     text = (pytesseract.image_to_string(Image.open('test.jpg'))).lower()\n",
    "    text = (pytesseract.image_to_string(frame)).lower()\n",
    "    \n",
    "    modified_list_words = pos_tag_sanity(text)\n",
    "\n",
    "    modified_urls = [ i + \"/\" + i + \"-abc.mp4\" if len(i) == 1 else i[0] + \"/\" + i + \".mp4\" if i != \"bye\" else \"bye-wave.mp4\" for i in modified_list_words]\n",
    "        \n",
    "    print(modified_list_words,modified_urls)\n",
    "    # Read URLs from handspeak.com\n",
    "    # https://github.com/esqu1/ASLetter    \n",
    "    for i, url in enumerate(modified_urls):\n",
    "        \n",
    "        cv2.imshow(WindowName,img3)\n",
    "        cv2.moveWindow(WindowName, 0, 0)\n",
    "        cv2.waitKey(delay = 1)\n",
    "                \n",
    "        if url in nonASLwords:\n",
    "            print('trying_dict')\n",
    "            letters = list(modified_list_words[i])\n",
    "            for j, l in enumerate(letters):\n",
    "                if l.isalpha():\n",
    "                    showvideo(\"letters/%s-abc.mp4\" % l, listToStr(modified_list_words[:i])+\" \"+ lettersToStr(letters[:j]) + \"*\"+ l + \"*\"+\n",
    "                                                     lettersToStr(letters[(j+1):]) +\" \"+ listToStr(modified_list_words[(i+1):])) \n",
    "                    \n",
    "        elif os.path.isfile(\"data/\" + url):\n",
    "            print(\"playing existing video\")\n",
    "            showvideo(\"data/\" + url, listToStr(modified_list_words[:i])+\" *\"+ modified_list_words[i] + \"* \"+ listToStr(modified_list_words[(i+1):])) \n",
    "        else:    \n",
    "            r = requests.get(\"https://handspeak.com/word/\" + url)\n",
    "            if r.text[:15] == \"<!DOCTYPE html>\":\n",
    "                nonASLwords.append(url)\n",
    "                letters = list(modified_list_words[i])\n",
    "                \n",
    "                for j, l in enumerate(letters):\n",
    "                    if l.isalpha():\n",
    "                        showvideo(\"letters/%s-abc.mp4\" % l, listToStr(modified_list_words[:i])+\" \"+ lettersToStr(letters[:j]) + \"*\"+ l + \"*\"+\n",
    "                                                     lettersToStr(letters[(j+1):]) +\" \"+ listToStr(modified_list_words[(i+1):])) \n",
    "                        \n",
    "            else: \n",
    "\n",
    "                f = open(\"data/\" + url, 'wb')\n",
    "                for chunk in r.iter_content(chunk_size=255):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "                f.close()\n",
    "                showvideo(\"data/\" + url, listToStr(modified_list_words[:i])+\" *\"+ modified_list_words[i] + \"* \"+ listToStr(modified_list_words[(i+1):])) \n",
    "\n",
    "    \n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "count = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    count += 1\n",
    "    if count%200 == 0:\n",
    "        count = count%200\n",
    "#         main(cv2.imread('test.jpg'))\n",
    "        main(frame)\n",
    "    if not ret:\n",
    "        print(\"Unable to capture video\")\n",
    "        break \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break            \n",
    "    \n",
    "    frame_1 = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)   \n",
    " \n",
    "    # Horizontally concatenate the 2 images\n",
    "    img3 = cv2.hconcat([loading_img,frame_1])\n",
    "\n",
    "    # Display the concatenated image\n",
    "    cv2.imshow(WindowName,img3)\n",
    "    cv2.moveWindow(WindowName, 0, 0)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"non_ASL_word_list.txt\", \"w\")\n",
    "f.write(\"\\'s\\shakespeare.mp4\\'\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('non_ASL_word_list.txt', 'r')\n",
    "nonASLwords = f.readlines()\n",
    "f.close()\n",
    "\n",
    "f = open(\"non_ASL_word_list.txt\", \"w\")\n",
    "nonASLtexts = ''.join([str(elem) for elem in nonASLwords]) \n",
    "f.write(nonASLtexts)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
